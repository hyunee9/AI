{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPC1zuKr3aB8N7Uo3pLSTiD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyunee9/AI/blob/main/%EC%8B%AC%EC%B8%B5%ED%95%99%EC%8A%B5_%EC%83%9D%EC%84%B1%EB%AA%A8%EB%8D%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 라이브러리"
      ],
      "metadata": {
        "id": "3TvlztUFQWoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim #gradient descent method를 이용할 것이니\n",
        "import torchvision # 영상 시각 지능에 특화된 라이브러리\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.utils import make_grid #결과 출력할 때 5x5 영상 크기로 만들려고\n",
        "from torch.utils.data import DataLoader #우리가 원하는 형식으로 데이터를 로딩할 수 있도록 도와주는\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "26SereNxQYab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. model 정의"
      ],
      "metadata": {
        "id": "nNet9SgvSO8j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 변수 설정"
      ],
      "metadata": {
        "id": "bMyBL3O4Sszd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_size = 62 #GAN의 입력으로 사용하는 데이터의 latent벡터의 크기\n",
        "hidden_size = 256 #GAN의 FC Layer, hidden layer에 속하는 노드의 갯수\n",
        "image_size = 28*28 #입력으로 사용하는 영상의 크기\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "qOUBocHKSuu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 generator"
      ],
      "metadata": {
        "id": "UxL_1cHETNkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#generator도 nn모델이기 때문에 nn.module을 상속받아서 만든다.\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__()\n",
        "    #fully connected layer이기 때문에 linear layer만 사용한다\n",
        "    # 3개의 fully  connected layer를 사용 -> ReLU, ReLU, Tanh\n",
        "    self.fc = nn.Sequential(\n",
        "        #1st FC : latenet_size -> hidden_size\n",
        "        nn.Linear(latent_size, hidden_size),\n",
        "        nn.ReLU(),\n",
        "        #2nd FC ; hidden_size -> hidden_size\n",
        "        #Linear : hidden을 받아서 hidden만큼 출력을 해준다\n",
        "        nn.Linear(hidden_size, hidden_size),\n",
        "        nn.ReLU(),\n",
        "        #3rd FC : hidden_size -> image_image\n",
        "        nn.Linear(hidden_size, image_size),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.fc(x)"
      ],
      "metadata": {
        "id": "p9CYObAaTO7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 discriminator"
      ],
      "metadata": {
        "id": "_HrwevbmTPQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.fc = nn.Sequential(\n",
        "        # 1st FC : image_size -> hidden_size / ReLU 사용\n",
        "        nn.Linear(image_size, hidden_size),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        # 2nd FC : hidden_size -> hidden_size / ReLU 사용\n",
        "        nn.Linear(hidden_size, hidden_size),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        # 3rd FC : hidden_size -> 1 / hidden_size로 부터 값을 뽑아내는데, 0~1 사이의 값이여야함.\n",
        "        #그래서 sigmoid함수를 이용한다.\n",
        "        nn.Linear(hidden_size, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.fc(x)"
      ],
      "metadata": {
        "id": "4K7lvr6QVF5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. data loading"
      ],
      "metadata": {
        "id": "2hXVeMpEWUwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean = [0.5], std = [0.5])])\n",
        "\n",
        "mnist = MNIST (root ='data/', train=True, transform=transform, download = True)\n",
        "\n",
        "#데이터를 훈련시키기 위해서 정해진 배치 사이즈만큼 잘라서 넣는 것.\n",
        "data_loader = DataLoader (dataset = mnist,\n",
        "                          batch_size = batch_size,\n",
        "                          shuffle = True,\n",
        "                          num_workers = 2,\n",
        "                          drop_last = True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA77eAJLWWkV",
        "outputId": "900da921-28d4-487d-d6b5-aff0ab3abe4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 35990241.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 1091696.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 8726346.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 6133460.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 초기 설정"
      ],
      "metadata": {
        "id": "t7HFCjAPXSMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 100\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)\n",
        "\n",
        "#loss 함수\n",
        "criterion = nn.BCELoss()\n",
        "d_optimizer = optim.Adam(D.parameters(), lr = 0.0002, betas = (0.5, 0.999))\n",
        "g_optimizer = optim.Adam(G.parameters(),lr = 0.0002, betas = (0.5, 0.999))"
      ],
      "metadata": {
        "id": "zf-5RQWkXSXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 결과 출력 함수 : image를(5x5)로 출력"
      ],
      "metadata": {
        "id": "2kxh-iCb1zZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(images, num_images = 25, size = (1, 28, 28)):\n",
        "  print(images.shape)\n",
        "  image_flat = images.detach().cpu().view(-1, *size)\n",
        "  image_grid = make_grid(image_flat[:num_images], nrow=5)\n",
        "  plt.imshow(image_grid.permute(1,2,0).squeeze())\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "nLkxOBwV18sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. 훈련"
      ],
      "metadata": {
        "id": "hE-cB1aB4FJ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. 실행"
      ],
      "metadata": {
        "id": "BIoB7zI98zgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# n_epochs 만큼 수행\n",
        "for epoch in range(n_epochs):\n",
        "  #data_loader에서 batch_size만큼 data 읽어오기\n",
        "  for i, (images, _) in enumerate(data_loader):\n",
        "    #1. flatten the images\n",
        "    images = images.reshape(batch_size, -1).to(device)\n",
        "    #to(device) : device로 보내서 GPU상에서 계산해달라는 뜻\n",
        "\n",
        "    #2. label 설정 : real -> 1, fake -> 0\n",
        "    real_labels = torch.ones(batch_size, 1).to(device)\n",
        "    fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "    #3. Discriminator 훈련\n",
        "\n",
        "    # 3.1 real image에 대한 loss 계산\n",
        "    #discriminator에 real image를 넣어서 결과를 출력\n",
        "    output = D(images)\n",
        "    #output에 대한 loss를 계산 : loss : y_hat와 y의 차이\n",
        "    # -> y_hat : output, y : real_labels\n",
        "    d_loss_real = criterion(output, real_labels)\n",
        "\n",
        "\n",
        "\n",
        "    #3.2 fkae image에 대한 loss 계산\n",
        "    #latent vector부터 생성\n",
        "    z = torch.randn(batch_size, latent_size).to(device)\n",
        "    #fake image 생성\n",
        "    fake_images = G(z)\n",
        "    #discriminator에 fake image를 넣어서 결과를 출력\n",
        "    output = D(fake_images.detach())\n",
        "    #.detach () : 더이상 미분하지 않겠다.\n",
        "    #loss 함수 구하기\n",
        "    d_loss_fake = criterion(output, fake_labels)\n",
        "\n",
        "    d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "    #3.3 gradient -> gradient descent\n",
        "    d_optimizer.zero_grad()\n",
        "    d_loss.backward()\n",
        "    d_optimizer.step()\n",
        "\n",
        "    #4. Generator를 훈련\n",
        "    #4.1 fake image를 생성해서 loss 계산\n",
        "    z = torch.randn(batch_size, latent_size).to(device)\n",
        "    #fake image 생성\n",
        "    fake_images = G(z)\n",
        "    #discriminator에 fake image를 넣어서 결과를 출력\n",
        "    output = D(fake_images)\n",
        "    g_loss = criterion(output, real_labels)\n",
        "\n",
        "    #4.2 gradient -> gradient descent\n",
        "    g_optimizer.zero_grad()\n",
        "    g_loss.backward()\n",
        "    g_optimizer.step()\n",
        "\n",
        "\n",
        "    show_images(fake_images) # 가짜 이미지\n",
        "    show_images(images) #실제 이미지\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "collapsed": true,
        "id": "MEctkkmD39W7",
        "outputId": "b47c6ce1-f579-4673-a31d-f75c7870bcf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'n_epochs' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-689816d4048d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# n_epochs 만큼 수행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;31m#data_loader에서 batch_size만큼 data 읽어오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#1. flatten the images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'n_epochs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.randn(batch_size, latent_size).to(device)\n",
        "fake_image = G(z)"
      ],
      "metadata": {
        "id": "Tlk2xvg981BB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}